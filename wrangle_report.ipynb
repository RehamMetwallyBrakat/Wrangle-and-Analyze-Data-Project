{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report\n",
    "\n",
    "###  &emsp;&emsp;&emsp;By Reham Metwally Maree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction :\n",
    "        \n",
    "        \n",
    "    The purpose of this project is to put in practice what I learned in data wrangling data. \n",
    "    The dataset that is wrangled is the tweet archive of Twitter user @dog_rates , also known\n",
    "    as WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about\n",
    "    the dog. These ratings almost always have a denominator of 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project details :\n",
    "\n",
    "\n",
    "    My tasks in this project are as follows:\n",
    "        1- Gathering data\n",
    "        2- Assessing data\n",
    "        3- Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering data\n",
    "\n",
    "    The data for this project consist on three different dataset that were obtained\n",
    "    as following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp;&emsp;Twitter archive file:\n",
    "\n",
    "        The twitter_archive_enhanced.csv was provided by Udacity and downloaded manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp;&emsp;Twitter API & JSON:\n",
    "            By using the tweet IDs in the WeRateDogs Twitter archive, I queried the Twitter API\n",
    "            for each tweet's JSON data using Python's Tweepy library and stored each tweet's \n",
    "            entire set of JSON data in a file called tweet_json.txt file. I read this .txt \n",
    "            file line by line into a pandas dataframe with tweet ID, favorite count, retweet\n",
    "            count, followers count, friends count, source, retweeted status and url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp;&emsp;The tweet image predictions:\n",
    "\n",
    "            Which breed of is present in each tweet according to a neural network. This file \n",
    "            (image_predictions.tsv) is hosted on Udacity's servers and was downloaded \n",
    "            programmatically using the Requests library and URL information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing data\n",
    "\n",
    "    Once the three tables were obtained I assessed the data as following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp;&emsp;Visually:\n",
    "\n",
    "        I used two tools:\n",
    "            1- by printing the three entire dataframes separate in Jupyter Notebook.\n",
    "            2- by checking the csv files in Excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &emsp;&emsp;Programmatically:\n",
    "\n",
    "        by using different methods (info, value_counts,sample, duplicated, groupby, ...)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then I separated the issues encountered in quality issues and tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data\n",
    "\n",
    "    This part of the data wrangling was divided in three parts:\n",
    "        1- Define\n",
    "        2- Code\n",
    "        3-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Copies of the original pieces of data are made prior to cleaning.\n",
    "#### - All issues identified in the assess phase are successfully cleaned using Python and pandas.\n",
    "#### - A tidy master dataset with all pieces of gathered data is created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing data\n",
    "\n",
    "    I Save master dataset to a CSV file.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis & Visualization\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    I made 3 insights and a visulization about the dataset after storing the datasets.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - I have used Python programming language and some of its packages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - There are several advantages of this tool (as compared to Excel) that is used by many data \n",
    "        scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - For gathering data there are several packages that help scraping data off the web, that\n",
    "        help using APIs to collect data (Tweepy for Twitter) or to communicate with SQL databases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - It is strong in dealing with big data (much better than Excel). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - It can deal with a large variety of data (unstructured data like JSON (Tweets) or also \n",
    "        structured data from ERP/SQL databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Handling, assessing, cleaning and visualizing of data is possible programmatically \n",
    "        using code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
